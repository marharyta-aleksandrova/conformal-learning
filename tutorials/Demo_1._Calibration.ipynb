{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19b8a799",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/marharyta-aleksandrova/conformal-learning/blob/main/tutorials/Demo_1._Calibration.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f20d373",
   "metadata": {},
   "source": [
    "Installing `nonconformist` library (uncomment the cells below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64c9e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/donlnz/nonconformist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97291a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd nonconformist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc76c6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb9c6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07eaea2",
   "metadata": {},
   "source": [
    "# Util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3014efaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy for a region prediction:\n",
    "# A region prediction produces an error if the resulting prediction set does not\n",
    "# contain the true value \n",
    "def get_accuracy(prediction, real_class):\n",
    "    correct = 0\n",
    "    N = len(prediction)\n",
    "    for i in range(0, N):\n",
    "        if prediction[i][real_class[i]]:\n",
    "            correct += 1\n",
    "    return correct / N\n",
    "\n",
    "# calculating metrics: oneC & avgC\n",
    "def get_oneC_avgC(prediction):\n",
    "    arr = np.array(prediction)\n",
    "    oneC = 0\n",
    "    avgC = 0\n",
    "    for i in range(0, len(arr)):\n",
    "        # number of predicted lables\n",
    "        num_predicted = arr[i].sum()\n",
    "        avgC += num_predicted\n",
    "        # is it a singleton?\n",
    "        if num_predicted == 1:\n",
    "            oneC += 1\n",
    "        pass\n",
    "    oneC /= len(arr)\n",
    "    avgC /= len(arr)\n",
    "    return oneC, avgC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f48b3bd",
   "metadata": {},
   "source": [
    "# Generating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f200d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(20)\n",
    "# centers of 2 classes\n",
    "centers = [\n",
    "    [ 1,  0],\n",
    "    [-1,  0],\n",
    "]\n",
    "\n",
    "# colors to plot members of different classes\n",
    "color_arr = ['r', 'b']\n",
    "\n",
    "# number of instances per class\n",
    "n_points = 5000\n",
    "# these arrays will store information about datapoints\n",
    "data_x = []\n",
    "data_y = []\n",
    "data_class = []\n",
    "data_color = []\n",
    "\n",
    "# standard deviation to generate the class instances\n",
    "sigma = 2.\n",
    "# data generation\n",
    "for class_val in range(0, len(centers)):\n",
    "    x, y = centers[class_val]\n",
    "    data_class.extend([class_val for j in range(0, n_points)])\n",
    "    data_color.extend([color_arr[class_val] for j in range(0, n_points)])\n",
    "    data_x.extend(np.random.normal(x, sigma, size=n_points))\n",
    "    data_y.extend(np.random.normal(y, sigma, size=n_points))\n",
    "# putting everything into a dataframe\n",
    "data_df = pd.DataFrame({\n",
    "    'x': data_x,\n",
    "    'y': data_y,\n",
    "    'class': data_class,\n",
    "    'color': data_color,\n",
    "})\n",
    "# plotting the dataset\n",
    "data_df.plot(\n",
    "    kind='scatter',\n",
    "    x='x',\n",
    "    y='y',\n",
    "    c=data_df['color'],\n",
    "    s=1,\n",
    "    grid=True,\n",
    "    figsize=(7,6),\n",
    ")\n",
    "\n",
    "# showing the centers in orange\n",
    "plt.scatter(np.array(centers).T[0], np.array(centers).T[1], s=70, c='orange', label='Centers')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03e65e2",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa8b838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fraction of the dataset to be used for testing\n",
    "test_frac = 0.1\n",
    "\n",
    "np.random.seed(2)\n",
    "# performing random permutation of the dataset\n",
    "idx = np.random.permutation(len(data_df))\n",
    "# constucting training and test datasets\n",
    "test_size = int(len(data_df) * 0.1)\n",
    "train_size = len(data_df) - test_size\n",
    "idx_train = idx[:train_size]\n",
    "idx_test = idx[train_size:]\n",
    "\n",
    "print('Size of training set: {}'.format(len(idx_train)))\n",
    "print('Size of test set: {}'.format(len(idx_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb0dabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(probability=True)\n",
    "\n",
    "model.fit(data_df[['x', 'y']].values[idx_train, :], data_df['class'].values[idx_train])\n",
    "prediction = model.predict(data_df[['x', 'y']].values[idx_test, :])\n",
    "acc = sum(prediction[:] == data_df['class'].values[idx_test][:]) / len(idx_test)\n",
    "print('Accuracy of prediction: {}%'.format(acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17fd6b0",
   "metadata": {},
   "source": [
    "Analysing probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fc9dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_result = model.predict_proba(data_df[['x', 'y']].values[idx_test, :])\n",
    "prob_result[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2956354",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3499002f",
   "metadata": {},
   "source": [
    "# Prediction with accuracy guarantees\n",
    "\n",
    "We need $95%$ accuracy, `significance = 0.05`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66860af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "significance = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61269d74",
   "metadata": {},
   "source": [
    "## Using probability estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d8f805",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_region_naive = prob_result > significance\n",
    "for i in range(0, 5):\n",
    "    print('{}: {}'.format(i + 1, prediction_region_naive[i]))\n",
    "\n",
    "acc = get_accuracy(prediction_region_naive, data_df['class'].values[idx_test])\n",
    "oneC, avgC = get_oneC_avgC(prediction_region_naive)\n",
    "print('Accuracy of the region predictor: {}%'.format(acc * 100))\n",
    "print('Efficiency:\\n\\t oneC = {}\\n\\t avgC = {}'.format(oneC, avgC))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3683bfa4",
   "metadata": {},
   "source": [
    "All labes are included for all instances. This predictor is of low value. Why does it happen?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffe1fe6",
   "metadata": {},
   "source": [
    "## Analysis of calibration curves\n",
    "\n",
    "Check [here](https://scikit-learn.org/stable/auto_examples/calibration/plot_calibration_curve.html) for the source code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7d5da2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV, CalibrationDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# saving data in arrays\n",
    "X_train, y_train = data_df[['x', 'y']].values[idx_train, :], data_df['class'].values[idx_train]\n",
    "X_test, y_test = data_df[['x', 'y']].values[idx_test, :], data_df['class'].values[idx_test]\n",
    "\n",
    "svm = SVC(probability=True)\n",
    "svm_isotonic = CalibratedClassifierCV(svm, cv=2, method=\"isotonic\")\n",
    "\n",
    "clf_list = [\n",
    "    (svm, \"SVM\"),\n",
    "    (svm_isotonic, \"SVM + Isotonic\"), \n",
    "    #(lr, \"Logistic\"),\n",
    "    #(gnb, \"Naive Bayes\"),\n",
    "    #(gnb_isotonic, \"Naive Bayes + Isotonic\"),\n",
    "]\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "gs = GridSpec(3, 2)\n",
    "colors = plt.cm.get_cmap(\"Dark2\")\n",
    "\n",
    "ax_calibration_curve = fig.add_subplot(gs[:2, :2])\n",
    "calibration_displays = {}\n",
    "for i, (clf, name) in enumerate(clf_list):\n",
    "    clf.fit(X_train, y_train)\n",
    "    display = CalibrationDisplay.from_estimator(\n",
    "        clf,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        n_bins=10,\n",
    "        name=name,\n",
    "        ax=ax_calibration_curve,\n",
    "        color=colors(i),\n",
    "    )\n",
    "    calibration_displays[name] = display\n",
    "\n",
    "ax_calibration_curve.grid()\n",
    "ax_calibration_curve.set_title(\"Calibration plots\")\n",
    "\n",
    "# Add histogram\n",
    "grid_positions = [(2, 0), (2, 1), (3, 0), (3, 1), (4, 0)]\n",
    "for i, (_, name) in enumerate(clf_list):\n",
    "    row, col = grid_positions[i]\n",
    "    ax = fig.add_subplot(gs[row, col])\n",
    "\n",
    "    ax.hist(\n",
    "        calibration_displays[name].y_prob,\n",
    "        range=(0, 1),\n",
    "        bins=10,\n",
    "        label=name,\n",
    "        color=colors(i),\n",
    "    )\n",
    "    ax.set(title=name, xlabel=\"Mean predicted probability\", ylabel=\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be20768",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C=1.0)\n",
    "gnb = GaussianNB()\n",
    "gnb_isotonic = CalibratedClassifierCV(gnb, cv=2, method=\"isotonic\")\n",
    "\n",
    "clf_list = [\n",
    "    #(svm, \"SVM\"),\n",
    "    #(svm_isotonic, \"SVM + Isotonic\"), \n",
    "    (lr, \"Logistic\"),\n",
    "    (gnb, \"Naive Bayes\"),\n",
    "    (gnb_isotonic, \"Naive Bayes + Isotonic\"),\n",
    "]\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "gs = GridSpec(4, 2)\n",
    "colors = plt.cm.get_cmap(\"Dark2\")\n",
    "\n",
    "ax_calibration_curve = fig.add_subplot(gs[:2, :2])\n",
    "calibration_displays = {}\n",
    "for i, (clf, name) in enumerate(clf_list):\n",
    "    clf.fit(X_train, y_train)\n",
    "    display = CalibrationDisplay.from_estimator(\n",
    "        clf,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        n_bins=10,\n",
    "        name=name,\n",
    "        ax=ax_calibration_curve,\n",
    "        color=colors(i),\n",
    "    )\n",
    "    calibration_displays[name] = display\n",
    "\n",
    "ax_calibration_curve.grid()\n",
    "ax_calibration_curve.set_title(\"Calibration plots\")\n",
    "\n",
    "# Add histogram\n",
    "grid_positions = [(2, 0), (2, 1), (3, 0), (3, 1), (4, 0)]\n",
    "for i, (_, name) in enumerate(clf_list):\n",
    "    row, col = grid_positions[i]\n",
    "    ax = fig.add_subplot(gs[row, col])\n",
    "\n",
    "    ax.hist(\n",
    "        calibration_displays[name].y_prob,\n",
    "        range=(0, 1),\n",
    "        bins=10,\n",
    "        label=name,\n",
    "        color=colors(i),\n",
    "    )\n",
    "    ax.set(title=name, xlabel=\"Mean predicted probability\", ylabel=\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc27866",
   "metadata": {},
   "source": [
    "## Conformal learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227f232d",
   "metadata": {},
   "source": [
    "Splitting data into test, train and calibration datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9c9732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fraction of the dataset to be used for testing\n",
    "test_frac = 0.1\n",
    "# fraction of the remaining dataset to be used for calibration\n",
    "calib_frac = 0.2\n",
    "\n",
    "np.random.seed(2)\n",
    "# random permulation\n",
    "idx = np.random.permutation(len(data_df))\n",
    "# constucting test, training and calibration datasets\n",
    "test_size = int(len(data_df) * test_frac) \n",
    "calib_size = int(len(data_df) * (1 - test_frac) * calib_frac)\n",
    "train_size = len(data_df) - test_size - calib_size\n",
    "idx_train, idx_cal, idx_test = idx[:train_size], idx[train_size:train_size + calib_size], idx[train_size + calib_size:]\n",
    "\n",
    "print('Test size: {}'.format(test_size))\n",
    "print('Calibration size: {}'.format(calib_size))\n",
    "print('Train size: {}'.format(train_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081ccf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nonconformist.cp import IcpClassifier\n",
    "from nonconformist.nc import NcFactory\n",
    "from nonconformist.nc import InverseProbabilityErrFunc, MarginErrFunc\n",
    "\n",
    "nc = NcFactory.create_nc(model, err_func=InverseProbabilityErrFunc())\t# Create a default nonconformity function\n",
    "icp = IcpClassifier(nc, smoothing=False)\t\t\t# Create an inductive conformal classifier\n",
    "\n",
    "# We comment this line to use the same underlying classifier that was built above.\n",
    "# Like this, we avoid deviations due to random initializations in the traning phase. \n",
    "# Fit the ICP using the proper training set\n",
    "icp.fit(data_df[['x', 'y']].values[idx_train, :], data_df['class'].values[idx_train])\n",
    "\n",
    "# Calibrate the ICP using the calibration set\n",
    "icp.calibrate(data_df[['x', 'y']].values[idx_cal, :], data_df['class'].values[idx_cal])\n",
    "\n",
    "# Produce predictions for the test set, with confidence 95%\n",
    "prediction_lib = icp.predict(data_df[['x', 'y']].values[idx_test, :], significance=significance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40738a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e702839",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = get_accuracy(prediction_lib, data_df['class'].values[idx_test])\n",
    "oneC, avgC = get_oneC_avgC(prediction_lib)\n",
    "print('Accuracy of the region predictor: {}%'.format(acc * 100))\n",
    "print('Efficiency:\\n\\t oneC = {}\\n\\t avgC = {}'.format(oneC, avgC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d22a29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
