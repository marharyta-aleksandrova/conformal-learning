{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "730cb674",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/marharyta-aleksandrova/conformal-learning/blob/main/tutorials/Exercise_1._Testing_conformal_classifiers.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8be5fa",
   "metadata": {},
   "source": [
    "Installing `nonconformist` library (uncomment the cells below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb34f32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/donlnz/nonconformist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdb3ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd nonconformist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb44819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python setup.py install"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1706d153",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d154459",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "from nonconformist.base import ClassifierAdapter\n",
    "from nonconformist.icp import IcpClassifier\n",
    "from nonconformist.nc import MarginErrFunc, InverseProbabilityErrFunc\n",
    "from nonconformist.nc import ClassifierNc\n",
    "from nonconformist.nc import NcFactory\n",
    "\n",
    "from nonconformist.evaluation import cross_val_score\n",
    "from nonconformist.evaluation import ClassIcpCvHelper\n",
    "from nonconformist.evaluation import class_avg_c, class_mean_errors, class_one_c, class_one_err, \\\n",
    "    class_mean_errors_one_class, class_one_err_one_class, class_mean_p_val, class_empty, n_test\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72694150",
   "metadata": {},
   "source": [
    "Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8446ee75",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc316d61",
   "metadata": {},
   "source": [
    "# Single run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdbd117",
   "metadata": {},
   "source": [
    "Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6680f8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "random.seed(10)\n",
    "\n",
    "# data permutation\n",
    "idx = np.random.permutation(data['target'].size)\n",
    "x, y = data['data'][idx, :], data['target'][idx]\n",
    "\n",
    "# Divide the data into training set and test set (20% for test => 150*0.2 = 30, 120 for training)\n",
    "test_len = int(len(data['target']) * 0.2)\n",
    "x_test, y_test = x[:test_len, ], y[:test_len, ]\n",
    "\n",
    "x_train_all, y_train_all = x[test_len:,], y[test_len:,]\n",
    "\n",
    "# devide data into validation and proper training sets (25% for validation => 120 * 0.25 = 30)\n",
    "# take only the 1st split\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.25)\n",
    "for train, cal in split.split(np.zeros((y_train_all.size, 1)), y_train_all):\n",
    "    break\n",
    "    \n",
    "x_cal, y_cal = x_train_all[cal,], y_train_all[cal,]\n",
    "x_train, y_train = x_train_all[train,], y_train_all[train,]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64af2b98",
   "metadata": {},
   "source": [
    "Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801ac9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100)\n",
    "nc = NcFactory.create_nc(model)\t# Create a default nonconformity function\n",
    "icp = IcpClassifier(nc, smoothing=False)\t\t\t# Create an inductive conformal classifier\n",
    "\n",
    "# Fit the ICP using the proper training set\n",
    "icp.fit(x_train, y_train)\n",
    "\n",
    "# Calibrate the ICP using the calibration set\n",
    "icp.calibrate(x_cal, y_cal)\n",
    "\n",
    "# Produce predictions for the test set (generating p-values)\n",
    "prediction_p = icp.predict(x_test)\n",
    "\n",
    "# Print the first 5 predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928bf964",
   "metadata": {},
   "source": [
    "Generating predictions for the required level of accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5422c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = prediction_p >= 0.1\n",
    "print(prediction_p[:5, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f4009d",
   "metadata": {},
   "source": [
    "# Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee036a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "icp = IcpClassifier(ClassifierNc(ClassifierAdapter(RandomForestClassifier(n_estimators=100))), \n",
    "                    smoothing=False)\n",
    "icp_cv = ClassIcpCvHelper(icp)\n",
    "\n",
    "np.random.seed(10)\n",
    "random.seed(10)\n",
    "\n",
    "scores = cross_val_score(icp_cv,\n",
    "                         data['data'],\n",
    "                         data['target'],\n",
    "                         iterations=1,\n",
    "                         folds=5,\n",
    "                         scoring_funcs=[\n",
    "                             class_mean_errors,\n",
    "                             class_avg_c,\n",
    "                             class_one_c,\n",
    "                             class_empty,\n",
    "                         ],\n",
    "                         significance_levels=[0.05, 0.1, 0.2],\n",
    "                         verbose=True,\n",
    "                         )\n",
    "\n",
    "print('Classification: iris')\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaaae69c",
   "metadata": {},
   "source": [
    "Averaging results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d248e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = scores.drop(['fold', 'iter'], axis=1)\n",
    "scores.groupby(['significance']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386ae439",
   "metadata": {},
   "source": [
    "# Tasks:\n",
    "\n",
    "1. Write functions for calculating `accuracy`, `avgC`, `oneC` and `emptyC`. Confirm that you get exacty the same results for the single run and for the 1st iteration of the 1st fold of cross-validation.\n",
    "2. Try SVM instead of Random Forest `model = SVC(probability=True)`.\n",
    "2. How do metrics depend on the number of folds and the number of iterations?\n",
    "3. Repeat the analysis above for the dataset defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bd0569",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(20)\n",
    "# centers of 4 classes\n",
    "centers = [\n",
    "    [ 1,  0],\n",
    "    [ 0,  1],\n",
    "    [-1,  0],\n",
    "    [ 0, -1],\n",
    "]\n",
    "\n",
    "# colors to plot members of different classes\n",
    "color_arr = ['r', 'b', 'g', 'y']\n",
    "\n",
    "# number of instances per class\n",
    "n_points = 5000\n",
    "# these arrays will store information about datapoints\n",
    "data_x = []\n",
    "data_y = []\n",
    "data_class = []\n",
    "data_color = []\n",
    "\n",
    "# standard deviation to generate the class instances\n",
    "sigma = 0.8\n",
    "# data generation\n",
    "for class_val in range(0, len(centers)):\n",
    "    x, y = centers[class_val]\n",
    "    data_class.extend([class_val for j in range(0, n_points)])\n",
    "    data_color.extend([color_arr[class_val] for j in range(0, n_points)])\n",
    "    data_x.extend(np.random.normal(x, sigma, size=n_points))\n",
    "    data_y.extend(np.random.normal(y, sigma, size=n_points))\n",
    "# putting everything into a dataframe\n",
    "data_df = pd.DataFrame({\n",
    "    'x': data_x,\n",
    "    'y': data_y,\n",
    "    'class': data_class,\n",
    "    'color': data_color,\n",
    "})\n",
    "# plotting the dataset\n",
    "data_df.plot(\n",
    "    kind='scatter',\n",
    "    x='x',\n",
    "    y='y',\n",
    "    c=data_df['color'],\n",
    "    s=1,\n",
    "    grid=True,\n",
    "    figsize=(7,6),\n",
    ")\n",
    "\n",
    "# showing the centers in orange\n",
    "plt.scatter(np.array(centers).T[0], np.array(centers).T[1], s=70, c='orange', label='Centers')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e54023d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'data': data_df[['x', 'y']].values, 'target': data_df['class'].values}\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15781be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
